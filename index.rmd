---
title: "Practical Machine Learning Final Project"
author: "Chris van Hasselt"
date: "February 28, 2016"
output: html_document
---

Personal fitness tracking devices from brands such as Fitbit, Jawbone, or Nike  quantify how much of a particular activity the device user performs. But they rarely quantify how well the user performs an activity. 

The aim of this machine learning project is to analyze personal fitness tracking data to determine the quality, rather than simply the quantity, of activity. Activity trackers use miniature accelerometers to track motion in three dimensions. 

The dataset includes data from accelerometers on the belt, forearm, and dumbbell of six participants.  Participants were asked to perform dumbbell lifts correctly and incorrectly in five different ways.  The analysis examines the data to develop a predictive model, and via that model distinguish correct form from incorrect form.

## Approach

Two datasets are provided for this project, a training and a testing set.  The approach used in this is analysis is to partition the training set, with 75% of the training set used for analysis and 25% used for testing of the derived model.  A second dataset is used independently to validate the predictive model.

Using the predictive model, the testing dataset will be analyzed to segregate good form from bad in the dumbbell lift activity.  The _classe_ variable (column 160) from dataset is used to identify whether an activity was performed correctly or not, and is used as the outcome variable to develop the training model. 


```{r message=FALSE}
# libraries used
library(caret)
library(Hmisc)

# read in the raw TRAINING data, to be subdivided into two datasets for developing the model.
rawData  <- read.csv("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",header=TRUE,sep=",")
rawTesting  <- read.csv("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",header=TRUE,sep=",")

partitions <- createDataPartition(y=rawData$classe,p=.75,list=FALSE)

training  <- rawData[partitions,]
testing   <- rawData[-partitions,]

```
## Choosing Data

The training dataset has 160 variables, 159 predictor candidate variables and one outcome variable, _classe_.  

Some of the predictor candidates are clearly not useful for prediction, for example the _X_ variable, essentially a row number, and the _user\_name_ variable.  Neither of these are relevant to whether the activity was 

It would be useful to reduce the number of variables further.  Using the nearZeroVar R function, I've identified all variables that are near zero, and removed those from the training set.  Further efforts to reduce the number of predictor variables could be employed to simplify the prediction model.


```{r message=FALSE}
# Remove the X and user_name variables
training <- training[,-match("X",names(training))]
training <- training[,-match("user_name",names(training))]

# remove variables that have near-zero variablity. This reduces the number of predictor candidate variables to 97.
nsvTrain <- nearZeroVar(training,saveMetrics=FALSE)
training <- training[,-nsvTrain]

# Repeat same process for testing
testing <- testing[,-match("X",names(testing))]
testing <- testing[,-match("user_name",names(testing))]

# remove variables that have near-zero variablity. This reduces the number of predictor candidate variables to 97.
testing <- testing[,-nsvTrain]

```

## Model Fitting & Prediction

A model based on the simplified dataset can be performed using random forest training. 


```{r message=FALSE,cache=TRUE}

# training using random forests to create a prediction model
modFitRF <- train(classe ~ .,data=training,method="rf")

modFitRF$results

# create a matrix of predictions for the testing data based random forest model.
predRF <- predict(modFitRF,newdata=testing)



```

At this point, I was very confused as to how to proceed further.  When attempting to have R construct a comparison table between the prediction and the actual values in the testing set, I was unable to 
get a comparison to validate that my prediction model was accurate. I believe this is because of the large number of "missed" predictions because of NA values, but am not sure how to proceed.

## Conclusion


The process I've outlined is a first-pass at prediction, a starting point for further exploration.  Given the time constraint for the class it is simply the best I can do with limited time.

